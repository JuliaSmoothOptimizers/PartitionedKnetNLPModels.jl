using LinearOperators, NLPModels, LinearAlgebra, LinearAlgebra.BLAS, Krylov
using Printf, SolverTools, SolverCore


PUS(nlp :: PartitionedKnetNLPModel; kwargs...) = partitioned_update_solver(nlp; is_KnetNLPModel=true, kwargs...)
function partitioned_update_solver(nlp :: AbstractNLPModel;
	x::AbstractVector=copy(nlp.meta.x0),
	T::DataType = eltype(x),
	kwargs...)
	n = nlp.meta.nvar
	B(nlp) = LinearOperator(T, n, n, true, true, (res, v)-> mul_prod!(res, nlp, v))
	type_update = nlp.name
	println("LinearOperator{$T} âœ… from $type_update")
	return partitioned_update_solver(nlp, B(nlp); x=x, kwargs...)
end

function partitioned_update_solver(nlp :: AbstractNLPModel, B :: AbstractLinearOperator{T};
  x::AbstractVector=copy(nlp.meta.x0),
	max_eval :: Int=10000,
	max_iter::Int=10000,
	start_time::Float64=time(),
	max_time :: Float64=30.0,
	Ïµ::Float64= 1e-6,
  printing::Bool=false,
  Î±=0.05,
	kwargs...) where T <: Number

	xâ‚€ = x
	n = length(xâ‚€)
  âˆ‡fâ‚€ = similar(xâ‚€)
	NLPModels.grad!(nlp, xâ‚€, âˆ‡fâ‚€; Î±)
	âˆ‡fNorm2 = norm(âˆ‡fâ‚€,2)

	println("Start trust-region PQN update using truncated conjugate-gradient, Î±=", Î±)
	(x, iter) = TRCG_KNLP_PUS(nlp, B; Î±, x, âˆ‡fâ‚€, max_eval=max_eval, max_time=max_time, kwargs...)

	printing && (io = open("src/optim/results/accuracy_PUS_" * string(nlp.name) * ".jl", "w+")	)
	printing && (write(io, string(nlp.counter.acc)))
	printing && (close(io))
	
	Î”t = time() - start_time
  g = similar(x)
	NLPModels.grad!(nlp, xâ‚€, g; Î±)
	nrm_grad = norm(g,2)

	absolute(n,gâ‚–,Ïµ) = nrm2(n,gâ‚–) < Ïµ
	relative(n,gâ‚–,Ïµ,âˆ‡fNorm2) = nrm2(n,gâ‚–) < Ïµ * âˆ‡fNorm2
	_max_iter(iter, max_iter) = iter >= max_iter
	_max_time(start_time) = (time() - start_time) >= max_time

	if absolute(n,g,Ïµ) || relative(n,g,Ïµ,âˆ‡fNorm2)
		status = :first_order
		println("point stationnaire âœ…")
	elseif _max_iter(iter, max_iter)
		status = :max_eval
		println("Max eval âŒ")
	elseif _max_time(start_time)
		status = :max_time
		println("Max time âŒ")
	else
		status = :unknown
		println("Unknown âŒ")
	end
	return GenericExecutionStats(nlp;
                         status, 
												 solution=x,
												 iter=iter,
												 dual_feas = nrm_grad,
												 objective = NLPModels.obj(nlp, x; Î±),
												 elapsed_time = Î”t,
												)
end


function TRCG_KNLP_PUS(nlp :: AbstractNLPModel, B :: AbstractLinearOperator{T};
	x::AbstractVector{T}=copy(nlp.meta.x0),
	n::Int=nlp.meta.nvar,
	max_eval::Int=10000,
	max_iter::Int=10000,
	max_time :: Float64=30.0,
	atol::Real=âˆšeps(eltype(x)),
	rtol::Real=âˆšeps(eltype(x)),
	start_time::Float64=time(),
	Î·::Float64=1e-3,
	Î·â‚::Float64=0.75, # > Î·
	Î”::Float64=1.,
	Ïµ::Float64=1e-6,
	Î´::Float64=1.,
	Ï•::Float64=2.,
  Î±::Float64=0.05,
	âˆ‡fâ‚€::AbstractVector=NLPModels.grad(nlp, nlp.meta.x0; Î±),
	iter_print::Int64=Int(floor(max_iter/100)),
	is_KnetNLPModel::Bool=false,
	verbose::Bool=true,
	data::Bool=true,
	kwargs...,
	) where T <: Number

	iter = 0 # â‰ˆ k
	gâ‚– = Vector{T}(undef,n); gâ‚– = âˆ‡fâ‚€
	gâ‚œâ‚˜â‚š = similar(gâ‚–)
	sâ‚– = similar(gâ‚–)
  xtmp = similar(gâ‚–)
	âˆ‡fNorm2 = nrm2(n, âˆ‡fâ‚€)

	fâ‚– = NLPModels.obj(nlp, x; Î±)
	verbose && @printf "iter temps fâ‚–      ||gâ‚–||    ||sâ‚–||    Î”     Ïâ‚–      /100 \n" 

	# cgtol = one(T)  # Must be â‰¤ 1.
	# cgtol = max(rtol, min(T(0.1), 9 * cgtol / 10, sqrt(âˆ‡fNorm2)))
  atol = (T)(0)
  cgtol = (T)(0)

	Ïâ‚– = -1

	# stop condition
	absolute(n,gâ‚–,Ïµ) = nrm2(n,gâ‚–) > Ïµ
	relative(n,gâ‚–,Ïµ,âˆ‡fNorm2) = nrm2(n,gâ‚–) > Ïµ * âˆ‡fNorm2
	_max_iter(iter, max_iter) = iter < max_iter
	_max_time(start_time) = (time() - start_time) < max_time
	while absolute(n,gâ‚–,Ïµ) && relative(n,gâ‚–,Ïµ,âˆ‡fNorm2) && _max_iter(iter, max_iter) & _max_time(start_time) && isnan(Ïâ‚–)==false# stop condition
		iter += 1
    fâ‚– = NLPModels.obj(nlp, x; Î±)
    NLPModels.grad!(nlp, x, gâ‚–; Î±)

		(verbose || data ) && (acc = KnetNLPModels.accuracy(nlp))
		verbose && @printf "%3d %4g %8.1e %7.1e %7.1e %7.1e %7.1e %8.3e " iter (time() - start_time) fâ‚– norm(gâ‚–,2) norm(sâ‚–,2) Î”  Ïâ‚– acc 
		data && push_acc!(nlp.counter, acc)
   
    gâ‚œâ‚˜â‚š .= .- gâ‚–
		cg_res = Krylov.cg(B, gâ‚œâ‚˜â‚š, atol=T(atol), rtol=cgtol, radius = T(Î”), itmax=max(2 * n, 50))
		sâ‚– .= cg_res[1]  # result of the linear system solved by Krylov.cg
    stats = cg_res[2]
    # @show stats

		(Ïâ‚–, fâ‚–â‚Šâ‚) = compute_ratio(x, fâ‚–, sâ‚–, nlp, B, gâ‚–; vec=xtmp, Î±) # we compute the ratio
		# step acceptance + update f,g
    if isnan(Ïâ‚–)
      @printf "Nan:âŒ"
    elseif Ïâ‚– > Î·
      xtmp .= x
			x .= x .+ sâ‚–
			epv_from_epv!(nlp.epv_work, nlp.epv_g)
			NLPModels.grad!(nlp, x, gâ‚–; Î±)
			minus_epv!(nlp.epv_work)
			add_epv!(nlp.epv_g, nlp.epv_work) # compute epv_y
			epv_from_v!(nlp.epv_s, sâ‚–)
			# PartitionedStructures.update!(nlp.eplom_B, nlp.epv_work, nlp.epv_s; name=nlp.name, verbose=false)
      PartitionedStructures.update!(nlp.eplom_B, nlp.epv_work, nlp.epv_s; name=nlp.name, verbose=true, reset=4)
			fâ‚– = fâ‚–â‚Šâ‚
			@printf "âœ…"
		else
			@printf "âŒ"
		end				
		# now we update âˆ†
		# !isnan(Ïâ‚–) && (Ïâ‚– >= Î·â‚) && ((norm(sâ‚–, 2) > 0.8*Î”) ? Î” = Ï•*Î” : Î” = Î”)
		# !isnan(Ïâ‚–) && (Ïâ‚– <= Î·) && (Î” = (1/Ï•)*Î”)
    if !isnan(Ïâ‚–)
      if (Ïâ‚– >= Î·â‚)
        if norm(sâ‚–, 2) > 0.8*Î”
          Î” = Ï•*Î” 
          @printf "â—‰ \n"
        else
          Î” = Î”
          @printf "â— \n"
        end
      elseif Ïâ‚– <= Î·
        Î” = (1/Ï•)*Î”
        @printf "ğŸ… \n"
      else
        @printf "â— \n"
      end
    end
		
		# change the minibatch
		is_KnetNLPModel && reset_minibatch_train!(nlp)
		
	end
	@printf "iter temps fâ‚– norm(gâ‚–,2) Î” Ïâ‚– accuracy\n" 
	@printf "%3d %4g %8.1e %7.1e %7.1e %7.1e %8.3e" iter (time() - start_time) fâ‚– norm(gâ‚–,2) Î”  Ïâ‚– KnetNLPModels.accuracy(nlp)

	return (x, iter)
end

function compute_ratio(x::Vector{T}, fâ‚–::T, sâ‚–::Vector{T}, nlp::AbstractNLPModel, B::AbstractLinearOperator{T}, gâ‚–::AbstractVector{T}; vec=similar(x), Î±=0.05) where T <: Number
  mul!(vec, B, sâ‚–) # Bâ‚–sâ‚–
	mâ‚–â‚Šâ‚ =  fâ‚– + dot(gâ‚–,sâ‚–) + 1/2 * (dot(vec, sâ‚–))
	vec .= x .+ sâ‚– # xâ‚–â‚Šâ‚
	fâ‚–â‚Šâ‚ = NLPModels.obj(nlp, vec; Î±)
  # @show fâ‚–, fâ‚–â‚Šâ‚, mâ‚–â‚Šâ‚, norm(sâ‚–)
	set_vars!(nlp, x)
	Ïâ‚– = (fâ‚– - fâ‚–â‚Šâ‚)/(fâ‚– - mâ‚–â‚Šâ‚)
	return (Ïâ‚–, fâ‚–â‚Šâ‚)
end